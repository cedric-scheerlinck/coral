{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9fed95-d21b-479c-9121-3fe597cc4198",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "from roifile import ImagejRoi\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from skimage.draw import polygon\n",
    "from skimage.transform import resize\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, LightningModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491b99b2-f386-4ff8-9ac7-13918bf0546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the large TIFF image\n",
    "base_path = Path('/home/cedric/coral')\n",
    "image_path = base_path / 'T1_22.12.06.tif'\n",
    "\n",
    "# Load the image using tifffile\n",
    "full_image = tifffile.imread(image_path)\n",
    "print(f\"Image shape: {full_image.shape}\")\n",
    "\n",
    "height, width, _ = full_image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b134cdb-3791-41da-a41d-373940592602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_roi(roi_files, image_shape):\n",
    "    # Initialize mask as a 2D array\n",
    "    mask = np.zeros(image_shape[:2], dtype=np.uint8)\n",
    "    height, width = image_shape[:2]\n",
    "\n",
    "    for roi_file in roi_files:\n",
    "        roi_path = os.path.join(roi_dir, roi_file)\n",
    "        roi = ImagejRoi.fromfile(roi_path)\n",
    "        \n",
    "        # Get the coordinates of the ROI\n",
    "        coords = roi.coordinates()\n",
    "        if coords is None or len(coords) == 0:\n",
    "            continue  # Skip if no coordinates\n",
    "        \n",
    "        # Convert coordinates to NumPy array\n",
    "        coords = np.array(coords, dtype=np.intp)\n",
    "        x_coords = coords[:, 0]\n",
    "        y_coords = coords[:, 1]\n",
    "        \n",
    "        # Ensure coordinates are within image bounds\n",
    "        if x_coords.max() >= width or y_coords.max() >= height:\n",
    "            print(f\"Coordinates exceed image dimensions in {roi_file}\")\n",
    "            continue  # Skip or adjust the coordinates\n",
    "        \n",
    "        # Fill the polygon in the mask\n",
    "        rr, cc = polygon(y_coords, x_coords, shape=mask.shape)\n",
    "        mask[rr, cc] = 1  # Assign a label value (e.g., 1)\n",
    "    \n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85069061-49d4-4c35-ad61-bc4a4b8e2633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing ROI files\n",
    "roi_dir = base_path / 'roi/'\n",
    "\n",
    "# List of ROI files\n",
    "roi_files = os.listdir(roi_dir)\n",
    "\n",
    "# Create the mask\n",
    "mask = create_mask_from_roi(roi_files, full_image.shape)\n",
    "print(\"Mask created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84770558-31c0-4915-963d-ab834946fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling factor\n",
    "factor = 20\n",
    "\n",
    "# For a NumPy image array 'image' and downsampling factor 'factor'\n",
    "def downsample_image_nearest(image, factor):\n",
    "    return image[::factor, ::factor, ...]\n",
    "\n",
    "# Example usage:\n",
    "downsampled_image = downsample_image_nearest(full_image, factor=20)\n",
    "\n",
    "# For the mask:\n",
    "# downsampled_mask = mask[::factor, ::factor]\n",
    "\n",
    "# Downsample the mask using block_reduce to preserve label values\n",
    "downsampled_mask = block_reduce(mask, block_size=(factor, factor), func=np.max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3dad7a-060a-4694-8ba4-a45f257a4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3552c692-5db4-42be-904f-f43bebf5b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'downsampled_image' and 'downsampled_mask' are already defined\n",
    "# 'downsampled_image' shape: (height, width, channels)\n",
    "# 'downsampled_mask' shape: (height, width), values 0 or 1\n",
    "\n",
    "# Define the overlay color (blue in this case)\n",
    "overlay_color = np.array([0, 0, 255], dtype=np.float32)  # Blue color in float32\n",
    "print(\"Overlay color shape:\", overlay_color.shape)  # Should be (3,)\n",
    "\n",
    "# Define the alpha blending factor\n",
    "alpha = 1  # Adjust the transparency (0.0 to 1.0)\n",
    "\n",
    "# Convert the image to float32 for blending and ensure it has 3 channels\n",
    "image_float = downsampled_image.astype(np.float32)[..., :3]\n",
    "print(\"Image shape:\", image_float.shape)  # Should be (height, width, 3)\n",
    "\n",
    "# Create an overlay image filled with the overlay color\n",
    "overlay = np.ones_like(image_float) * overlay_color  # Shape: (height, width, 3)\n",
    "\n",
    "# Create a mask for blending and expand dimensions to match image channels\n",
    "mask_3d = downsampled_mask[:, :, np.newaxis]  # Shape: (height, width, 1)\n",
    "print(\"Mask shape:\", mask_3d.shape)  # Should be (height, width, 1)\n",
    "\n",
    "# Perform alpha blending only on the masked areas\n",
    "image_blend = np.where(mask_3d, \n",
    "                       (1 - alpha) * image_float + alpha * overlay, \n",
    "                       image_float)\n",
    "\n",
    "# Convert back to uint8\n",
    "image_with_overlay = image_blend.astype(np.uint8)\n",
    "\n",
    "# Display the result\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(image_with_overlay)\n",
    "plt.title('Downsampled Image with Masked Areas in Blue')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28799969-3989-4b90-945a-e2926d3c0fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "plt.imshow(downsampled_image)\n",
    "plt.imshow(downsampled_mask, cmap='jet', alpha=0.5)\n",
    "plt.title('Downsampled Image with Mask Overlay')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0720ed-8e10-4890-974c-4e31afd763ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
